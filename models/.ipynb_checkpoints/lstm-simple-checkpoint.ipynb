{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benza-ord\\source\\repos\\CS583-Research-Project\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "      <th>result</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "      <th>tweet_clst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:28:53-05:00</td>\n",
       "      <td>Kirkpatrick, who wore a baseball cap embroider...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136</td>\n",
       "      <td>['Kirkpatrick', 'wear', 'baseball', 'cap', 'em...</td>\n",
       "      <td>Kirkpatrick who wore a baseball cap embroidere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:04:30-05:00</td>\n",
       "      <td>#&lt;e&gt;obama&lt;/e&gt; debates that Cracker Ass Cracker...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88</td>\n",
       "      <td>['obama', 'debate', 'Cracker', 'Ass', 'Cracker...</td>\n",
       "      <td>obama debates that Cracker Ass Cracker tonight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>09:50:08-05:00</td>\n",
       "      <td>@Hollivan @hereistheanswer  Youre missing the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>['Hollivan', 'hereistheanswer', 'Youre', 'miss...</td>\n",
       "      <td>Hollivan hereistheanswer Youre missing the poi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:00:16-05:00</td>\n",
       "      <td>I was raised as a Democrat  left the party yea...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146</td>\n",
       "      <td>['raise', 'Democrat', 'leave', 'party', 'years...</td>\n",
       "      <td>I was raised as a Democrat left the party year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>09:48:07-05:00</td>\n",
       "      <td>The &lt;e&gt;Obama camp&lt;/e&gt; can't afford to lower ex...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124</td>\n",
       "      <td>['Obama', 'camp', 'ca', 'afford', 'lower', 'ex...</td>\n",
       "      <td>The Obama camp ca n't afford to lower expectat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date            time  \\\n",
       "0  2012-10-16 00:00:00  10:28:53-05:00   \n",
       "1  2012-10-16 00:00:00  10:04:30-05:00   \n",
       "2  2012-10-16 00:00:00  09:50:08-05:00   \n",
       "3  2012-10-16 00:00:00  10:00:16-05:00   \n",
       "4  2012-10-16 00:00:00  09:48:07-05:00   \n",
       "\n",
       "                                               tweet  class  result  \\\n",
       "0  Kirkpatrick, who wore a baseball cap embroider...      0     NaN   \n",
       "1  #<e>obama</e> debates that Cracker Ass Cracker...      1     NaN   \n",
       "2  @Hollivan @hereistheanswer  Youre missing the ...      0     NaN   \n",
       "3  I was raised as a Democrat  left the party yea...     -1     NaN   \n",
       "4  The <e>Obama camp</e> can't afford to lower ex...      0     NaN   \n",
       "\n",
       "   tweet_length                                      tweet_cleaned  \\\n",
       "0           136  ['Kirkpatrick', 'wear', 'baseball', 'cap', 'em...   \n",
       "1            88  ['obama', 'debate', 'Cracker', 'Ass', 'Cracker...   \n",
       "2           140  ['Hollivan', 'hereistheanswer', 'Youre', 'miss...   \n",
       "3           146  ['raise', 'Democrat', 'leave', 'party', 'years...   \n",
       "4           124  ['Obama', 'camp', 'ca', 'afford', 'lower', 'ex...   \n",
       "\n",
       "                                          tweet_clst  \n",
       "0  Kirkpatrick who wore a baseball cap embroidere...  \n",
       "1  obama debates that Cracker Ass Cracker tonight...  \n",
       "2  Hollivan hereistheanswer Youre missing the poi...  \n",
       "3  I was raised as a Democrat left the party year...  \n",
       "4  The Obama camp ca n't afford to lower expectat...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"cxs583_cleaned_file_v2.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert tweet_clst to string\n",
    "df['tweet_clst'] = df['tweet_clst'].astype(str)\n",
    "\n",
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_VOCAB_SIZE = 50000\n",
    "# Max number of words in each tweet.\n",
    "MAX_SEQUENCE_LENGTH = 75\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "RANDOM_SEED = 42\n",
    "# split 90-10 train-test\n",
    "df_train, df_test = train_test_split(df, test_size=0.1, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18759 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words= MAX_VOCAB_SIZE, filters='#$%&()*+<=>@[\\\\]^_`{|}~\\t\\n', lower=True)\n",
    "tokenizer.fit_on_texts(df_train['tweet_clst'])\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (10145, 75)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(df_train['tweet_clst'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (10145, 3)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(df_train['class']).values\n",
    "print('Shape of label tensor:', Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "318/318 [==============================] - 16s 50ms/step - loss: 0.5682 - accuracy: 0.5337\n",
      "Epoch 2/10\n",
      "318/318 [==============================] - 16s 49ms/step - loss: 0.4174 - accuracy: 0.7102\n",
      "Epoch 3/10\n",
      "318/318 [==============================] - 16s 50ms/step - loss: 0.2513 - accuracy: 0.8440\n",
      "Epoch 4/10\n",
      "318/318 [==============================] - 16s 50ms/step - loss: 0.1516 - accuracy: 0.9103\n",
      "Epoch 5/10\n",
      "318/318 [==============================] - 16s 50ms/step - loss: 0.1002 - accuracy: 0.9439\n",
      "Epoch 6/10\n",
      "318/318 [==============================] - 16s 49ms/step - loss: 0.0729 - accuracy: 0.9603\n",
      "Epoch 7/10\n",
      "318/318 [==============================] - 17s 53ms/step - loss: 0.0533 - accuracy: 0.9706\n",
      "Epoch 8/10\n",
      "318/318 [==============================] - 16s 52ms/step - loss: 0.0435 - accuracy: 0.9744\n",
      "Epoch 9/10\n",
      "318/318 [==============================] - 17s 53ms/step - loss: 0.0362 - accuracy: 0.9804\n",
      "Epoch 10/10\n",
      "318/318 [==============================] - 17s 53ms/step - loss: 0.0280 - accuracy: 0.9848\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_VOCAB_SIZE, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(LSTM(EMBEDDING_DIM, dropout = 0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# run for small number of epochs then save \n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(X, Y, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (1128, 75)\n",
      "Shape of label tensor: (1128, 3)\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 1.5411 - accuracy: 0.5390\n",
      "loss 1.541121482849121\n",
      "accuracy 0.5390070676803589\n"
     ]
    }
   ],
   "source": [
    "X_test = tokenizer.texts_to_sequences(df_test['tweet_clst'].values)\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X_test.shape)\n",
    "\n",
    "Y_Test = pd.get_dummies(df_test['class']).values\n",
    "print('Shape of label tensor:', Y_Test.shape)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, Y_Test)\n",
    "\n",
    "print(\"loss\",loss)\n",
    "print(\"accuracy\",accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.59      0.58      0.59       455\n",
      "           0       0.48      0.54      0.51       380\n",
      "           1       0.53      0.47      0.50       293\n",
      "\n",
      "    accuracy                           0.54      1128\n",
      "   macro avg       0.54      0.53      0.53      1128\n",
      "weighted avg       0.54      0.54      0.54      1128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# get the class with highest probability for each sample\n",
    "y_pred = np.argmax(predictions, axis=-1) - 1\n",
    "\n",
    "print(classification_report(df_test['class'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-gpu-kernel",
   "language": "python",
   "name": "keras-gpu-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
