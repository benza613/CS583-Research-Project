{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPyAj6RAei8OxpCdS6V48qD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benza613/CS583-Research-Project/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNz3Khjwp-Fc"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/gdrive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "\n",
        "drive.mount(ROOT) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OGifbfWJi9E"
      },
      "source": [
        "%cd CS583-Research-Project/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JfwO1eQJoDU"
      },
      "source": [
        "#Data Analysis\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#Data Preprocessing and Feature Engineering\n",
        "from textblob import TextBlob\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "\n",
        "\n",
        "\n",
        "!pip install tweet-preprocessor\n",
        "import preprocessor as p\n",
        "\n",
        "#Model Selection and Validation\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0NJW0tFJou0"
      },
      "source": [
        "df = pd.read_csv(\"cxs583_cleaned_file_v2.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHYuP4D_KCA8"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvnCJjl7KW_6"
      },
      "source": [
        "df['tweet_clst'] = df['tweet_clst'].apply(lambda _: str(_))\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gf2kNAAKOcf"
      },
      "source": [
        "sentiment_label = df['class'].factorize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PJnTM4vKywd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fM9jmlFKSHF"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "tweet = df.tweet_cleaned.values\n",
        "tokenizer = Tokenizer(num_words=50000)\n",
        "tokenizer.fit_on_texts(tweet)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "encoded_docs = tokenizer.texts_to_sequences(tweet)\n",
        "padded_sequence = pad_sequences(encoded_docs, maxlen=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ABinLYuKzYd"
      },
      "source": [
        "print(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVwTVidLK0Hs"
      },
      "source": [
        "print(tweet[0])\n",
        "print(encoded_docs[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D3uZq24K29g"
      },
      "source": [
        "print(padded_sequence.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3Av0c2DKVNr"
      },
      "source": [
        "# Build the model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.layers import SpatialDropout1D\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding_vector_length = 200\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_vector_length,     \n",
        "                                     input_length=200) )\n",
        "model.add(SpatialDropout1D(0.25))\n",
        "model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam', \n",
        "                           metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq62A92mKi1C"
      },
      "source": [
        "history = model.fit(padded_sequence,df['class'], epochs=2, batch_size=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvQH6yOIbOMr"
      },
      "source": [
        "filePath = \"model.h5\"\n",
        "model.save(filePath)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}